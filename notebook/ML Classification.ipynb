{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fffca616",
   "metadata": {},
   "source": [
    "## ML Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6205f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde7ee32",
   "metadata": {},
   "source": [
    "## Featrue Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c060b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 16000\n",
    "n_fft = int(0.025 * sampling_rate)\n",
    "win_length = int(0.025 * sampling_rate)\n",
    "hop_length = int(0.01 * sampling_rate)\n",
    "n_mels = 96\n",
    "n_mfcc = 13\n",
    "melkwargs={\n",
    "      'n_fft': n_fft,\n",
    "      'n_mels': n_mels,\n",
    "      'hop_length': hop_length,\n",
    "    }\n",
    "dirs = \"../dataset/feature/npy\"\n",
    "fnames = os.listdir(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d5159fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:53<00:00,  9.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "features = {}\n",
    "rms_dict = {}\n",
    "pitch_dict = {}\n",
    "mfccs_dict = {}\n",
    "for fname in tqdm(fnames):\n",
    "    _id = fname.replace(\".npy\",\"\")\n",
    "    y = np.load(os.path.join(dirs, fname))\n",
    "    mfcc_emb = librosa.feature.mfcc(\n",
    "        y = y.squeeze(0), \n",
    "        n_mfcc =n_mfcc,\n",
    "        sr=sampling_rate, \n",
    "        n_fft=n_fft, \n",
    "        hop_length=hop_length, \n",
    "        n_mels=n_mels,\n",
    "    )\n",
    "    mean_mfcc = list(mfcc_emb.mean(axis=1)) # temporal pooling\n",
    "    std_mfcc = list(mfcc_emb.std(axis=1)) # temporal pooling\n",
    "    pitchs = F.detect_pitch_frequency(torch.from_numpy(y.squeeze(0)), sampling_rate).numpy()\n",
    "    mean_pitch = pitch.mean()\n",
    "    std_pitch = pitch.std()\n",
    "    rms = librosa.feature.rms(y=y.squeeze(0))\n",
    "    mean_rms = rms.mean()\n",
    "    std_rms = rms.std()\n",
    "    feature = mean_mfcc + std_mfcc + [mean_pitch, std_pitch, mean_rms, std_rms]\n",
    "    features[_id] = feature\n",
    "    rms_dict[_id] = rms\n",
    "    pitch_dict[_id] = pitch\n",
    "    mfccs_dict[_id] = mfcc_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37f0fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(features, \"../dataset/feature/handcraft/all_features.pt\")\n",
    "torch.save(rms_dict, \"../dataset/feature/handcraft/energy.pt\")\n",
    "torch.save(pitch_dict, \"../dataset/feature/handcraft/pitch.pt\")\n",
    "torch.save(mfccs_dict, \"../dataset/feature/handcraft/mfccs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ef8bad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714 0.46977124183006536\n",
      "0.5084745762711864 0.5068627450980392\n",
      "0.55 0.484375\n",
      "0.42424242424242425 0.4\n",
      "0.5416666666666666 0.4494949494949495\n",
      "0.6865671641791045 0.6739028944911298\n",
      "0.8064516129032258 0.7879464285714286\n",
      "0.4 0.4035947712418301\n"
     ]
    }
   ],
   "source": [
    "fold_case = ['M1','M2','M3','M4','F5','F6','F7','F8']\n",
    "all_samples = []\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "label_dist = {}\n",
    "for fold in fold_case:\n",
    "    df_tr = pd.read_csv(f\"../dataset/split/{fold}_train.csv\",index_col=0)\n",
    "    df_va = pd.read_csv(f\"../dataset/split/{fold}_valid.csv\",index_col=0)\n",
    "    df_train = pd.concat([df_tr, df_va])\n",
    "    df_eval = pd.read_csv(f\"../dataset/split/{fold}_eval.csv\",index_col=0)\n",
    "    label_dist[fold] = {\"tr\":df_train.sum(), \"te\":df_eval.sum()}\n",
    "    X_train = np.stack([features[idx] for idx in df_train.index])\n",
    "    y_train = np.stack(list(df_train.idxmax(axis=1)))\n",
    "    X_test = np.stack([features[idx] for idx in df_eval.index])\n",
    "    y_test = np.stack(list(df_eval.idxmax(axis=1)))\n",
    "    \n",
    "    classifier = make_pipeline(StandardScaler(),LogisticRegression(random_state=42))\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    WA = accuracy_score(y_test, predictions)\n",
    "    UA = balanced_accuracy_score(y_test, predictions)\n",
    "    print(WA, UA)\n",
    "    # WA, UA evaluation\n",
    "    all_labels.extend(list(y_test))\n",
    "    all_preds.extend(list(predictions))\n",
    "    all_samples.extend(list(df_eval.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f18e6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=all_samples)\n",
    "results['all_preds'] = all_preds\n",
    "results['all_labels'] = all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aea96def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_acc & un-weighted acc\n",
    "WA = accuracy_score(results['all_labels'], results['all_preds'])\n",
    "UA = balanced_accuracy_score(results['all_labels'], results['all_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1dbc6ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5594262295081968, 0.5499829405904139)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WA, UA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a50eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
