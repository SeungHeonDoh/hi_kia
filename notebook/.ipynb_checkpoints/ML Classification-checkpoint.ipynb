{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e259eec",
   "metadata": {},
   "source": [
    "## ML Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "021ad8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hi_kia/env/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3189bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F7 426 62\n",
      "M2 429 59\n",
      "M4 422 66\n",
      "F8 418 70\n",
      "F5 440 48\n",
      "M1 432 56\n",
      "F6 421 67\n",
      "M3 428 60\n"
     ]
    }
   ],
   "source": [
    "df_annotation = pd.read_csv(\"../dataset/split/annotation.csv\", index_col=0)\n",
    "for gen_pid in set(df_annotation['gen_pid']):\n",
    "    EVAL_item = df_annotation[df_annotation['gen_pid'] == gen_pid].index\n",
    "    TRAIN_item = df_annotation[df_annotation['gen_pid'] != gen_pid].index\n",
    "    df_annotation.loc[TRAIN_item]\n",
    "    df_annotation.loc[EVAL_item]\n",
    "    print(gen_pid, len(TRAIN_item), len(EVAL_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed1df0",
   "metadata": {},
   "source": [
    "## Featrue Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af48c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000\n",
    "n_fft = int(0.025 * sr)\n",
    "win_length = int(0.025 * sr)\n",
    "hop_length = int(0.01 * sr)\n",
    "n_mels = 96\n",
    "n_mfcc = 13\n",
    "melkwargs={\n",
    "      'n_fft': n_fft,\n",
    "      'n_mels': n_mels,\n",
    "      'hop_length': hop_length,\n",
    "    }\n",
    "dirs = \"../dataset/wav\"\n",
    "fnames = os.listdir(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c953e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "features = {}\n",
    "rms_dict = {}\n",
    "pitch_dict = {}\n",
    "mfccs_dict = {}\n",
    "for fname in tqdm(fnames):\n",
    "    _id = fname.replace(\".npy\",\"\")\n",
    "    y = np.load(os.path.join(dirs, fname))\n",
    "    mfcc_emb = librosa.feature.mfcc(\n",
    "        y.squeeze(0), \n",
    "        n_mfcc =n_mfcc,\n",
    "        sr=sampling_rate, \n",
    "        n_fft=n_fft, \n",
    "        hop_length=hop_length, \n",
    "        n_mels=n_mels,\n",
    "    )\n",
    "    mean_mfcc = list(mfcc_emb.mean(axis=1)) # temporal pooling\n",
    "    std_mfcc = list(mfcc_emb.std(axis=1)) # temporal pooling\n",
    "    pitchs = F.detect_pitch_frequency(torch.from_numpy(y.squeeze(0)), sr).numpy()\n",
    "    pitch = np.array([i for i in pitchs if i < 1000])\n",
    "    mean_pitch = pitch.mean()\n",
    "    std_pitch = pitch.std()\n",
    "    rms = librosa.feature.rms(y=y.squeeze(0))\n",
    "    mean_rms = rms.mean()\n",
    "    std_rms = rms.std()\n",
    "    feature = mean_mfcc + std_mfcc + [mean_pitch, std_pitch, mean_rms, std_rms]\n",
    "    features[_id] = feature\n",
    "    rms_dict[_id] = rms\n",
    "    pitch_dict[_id] = pitch\n",
    "    mfccs_dict[_id] = mfcc_emba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e43a3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = []\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "label_dist = {}\n",
    "for fold in fold_case:\n",
    "    df_tr = pd.read_csv(f\"../dataset/split/{fold}_train.csv\",index_col=0)\n",
    "    df_va = pd.read_csv(f\"../dataset/split/{fold}_valid.csv\",index_col=0)\n",
    "    df_train = pd.concat([df_tr, df_va])\n",
    "    df_eval = pd.read_csv(f\"../dataset/split/{fold}_eval.csv\",index_col=0)\n",
    "    label_dist[fold] = {\"tr\":df_train.sum(), \"te\":df_eval.sum()}\n",
    "    X_train = np.stack([features[idx] for idx in df_train.index])\n",
    "    y_train = np.stack([df_train.loc[idx].idxmax() for idx in df_train.index])\n",
    "    X_test = np.stack([features[idx] for idx in df_eval.index])\n",
    "    y_test = np.stack([df_eval.loc[idx].idxmax() for idx in df_eval.index])\n",
    "    classifier = make_pipeline(StandardScaler(),LogisticRegression(random_state=42))\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    WA = accuracy_score(y_test, predictions)\n",
    "    print(WA)\n",
    "    # WA, UA evaluation\n",
    "    all_labels.extend(list(y_test))\n",
    "    all_preds.extend(list(predictions))\n",
    "    all_samples.extend(list(df_eval.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1972c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=all_samples)\n",
    "results['all_preds'] = all_preds\n",
    "results['all_labels'] = all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ca4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_acc & un-weighted acc\n",
    "WA = accuracy_score(results['all_labels'], results['all_preds'])\n",
    "UA = balanced_accuracy_score(results['all_labels'], results['all_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a03c32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
